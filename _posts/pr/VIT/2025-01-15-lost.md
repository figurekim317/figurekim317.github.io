---
layout: post
title: "[Paper review] Localizing Objects with Self-Supervised Transformers
and no Labels"
last_modified_at: 2025-01-15
mathjax: true
image:  /assets/images/blog/post-5.jpg
categories:
  - 논문리뷰
tags:
  - ViT
  - Computer Vision
  - Self-Supervised Learning
  - AI
excerpt: "LOST paper review"
use_math: true
classes: wide
---


> [[Paper](https://arxiv.org/abs/2109.14279)] [[Github](https://github.com/valeoai/LOST)]  
> Oriane Sim´ eoni, Gilles Puy, Huy V. Vo, Simon Roburin, Spyros Gidaris1, Andrei
Bursuc, Patrick P´erez, Renaud Marlet and Jean Ponce
> Valeo.ai |  Inria | LIGM | Center for Data Science, New York University  
> BMVC 2021

<figure>
  <div style="text-align:center">
    <img src="/assets/img/lost/fig1.png" alt="Fig 1" style="width:80%;">
  </div>
</figure>

--

### Introduction
Object detector는 자율주행 차량과 같은 핵심 시스템에서 중요한 역할을 합니다. 하지만 높은 성능을 달성하기 위해서는 대량의 annotated data를 필요로 합니다. 이러한 비용을 줄이기 위한 다양한 접근법이 제안되었으며, 예를 들어 semi-supervision, weak supervision, active learning, 그리고 self-supervision 기반의 task fine-tuning 등이 있다.

본 연구에서는 **annotation 없이 이미지를 통해 object의 localizing**하는 방법을 다룬다. 초기 연구들은 **saliency** 또는 이미지 내 유사성(intra-image similarity)만을 활용했으나, 이는 정확도가 낮고 제안된 영역이 너무 많아 대규모 데이터셋에는 적합하지 않았습니다. 일부 접근법은 주석 없이 다른 데이터 소스(예: 오디오, LiDAR) 등을 활용하기도 했습니다.

이에 대해, 우리는 **단일 이미지 수준에서 객체를 로컬라이즈**하는 간단한 방법을 제안합니다. 이 방법은 이미지 간 유사성을 탐색하지 않기 때문에 선형적인 복잡도를 가지며, 대규모 데이터셋에서도 높은 확장성을 가집니다.

## 2. 주요 아이디어
우리의 접근법은 **DINO(Self-supervised Vision Transformer)**에서 학습된 고품질 특징을 활용합니다. 구체적으로:
1. 이미지를 동일한 크기의 패치로 나눕니다.
2. DINO 모델을 통해 각 패치의 특징을 추출합니다.
3. 마지막 주의(attention) 레이어에서 얻은 키(key) 요소를 사용하여 패치 간 유사도를 계산합니다.
4. **유사한 패치 수가 가장 적은 패치(Seed)**를 선택해 객체의 일부를 로컬라이즈합니다. 이는 전경 객체의 패치가 배경 패치보다 상관성이 낮다는 경험적 관찰에 기반합니다.
5. 초기 Seed에 대해 유사성이 높은 패치를 추가하며, 이를 **Seed 확장(Seed Expansion)**이라고 합니다.
6. 최종적으로 이 과정을 통해 **바이너리 객체 분할 마스크**를 생성하고, 연결된 가장 큰 구성 요소에 대해 **바운딩 박스**를 추론합니다.

## 3. 성과 및 기여
이 간단한 방법론을 통해 다음과 같은 주요 성과를 달성했습니다:
1. **영역 제안(region proposals)** 및 단일 객체 발견(single-object discovery) 방법론을 능가하는 성능을 보였습니다.
2. 제안된 바운딩 박스를 **주석 데이터로 활용해 클래스에 구애받지 않는(class-agnostic) 객체 탐지기**를 학습시켰습니다. 이를 통해 단일 이미지에서 다중 객체를 정확히 탐지할 수 있었습니다.
3. 객체를 시각적으로 일관된 클래스로 그룹화(clustering)하여 **클래스 인식(class-aware) 객체 탐지기**를 학습시켰습니다.
4. 일부 클러스터는 데이터셋의 라벨된 의미적 클래스와 높은 상관성을 보여, 약지도 학습 수준의 객체 탐지 결과를 달성했습니다.

## 4. 주요 기여
이 연구의 주요 기여는 다음과 같습니다:
1. 자가 지도 학습된 비전 트랜스포머에서 특징을 추출하고, **이미지 내 패치 상관성**을 활용하여 단일 객체 로컬라이제이션 방법을 제안했습니다. 이 방법은 데이터셋 크기에 대해 선형 복잡도를 가집니다.
2. 클래스에 구애받지 않는(class-agnostic) 및 클래스 인식(class-aware) 객체 탐지기를 학습시켜, 다중 객체 로컬라이제이션 및 시맨틱 클래스 그룹화를 달성했습니다.
3. **비지도 객체 탐지(unsupervised object discovery)**에서 기존의 연구를 큰 폭으로 능가하는 성과를 보였습니다.

이 연구는 비지도 학습의 잠재력을 보여주며, 대규모 데이터셋에 주석을 달지 않고도 정확한 객체 탐지를 가능하게 한다는 점에서 큰 의미를 갖습니다.
