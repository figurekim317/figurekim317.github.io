---
layout: post
title: "[Paper review] Localizing Objects with Self-Supervised Transformers
and no Labels"
last_modified_at: 2025-01-15
mathjax: true
image:  /assets/images/blog/post-5.jpg
categories:
  - 논문리뷰
tags:
  - ViT
  - Computer Vision
  - Self-Supervised Learning
  - AI
excerpt: "LOST paper review"
use_math: true
classes: wide
---


> [[Paper](https://arxiv.org/abs/2109.14279)] [[Github](https://github.com/valeoai/LOST)]  
> Oriane Sim´ eoni, Gilles Puy, Huy V. Vo, Simon Roburin, Spyros Gidaris1, Andrei
Bursuc, Patrick P´erez, Renaud Marlet and Jean Ponce
> Valeo.ai |  Inria | LIGM | Center for Data Science, New York University  
> BMVC 2021

<figure>
  <div style="text-align:center">
    <img src="/assets/img/lost/fig1.png" alt="Fig 1" style="width:80%;">
  </div>
</figure>

--

### Introduction
Object detector는 자율주행 차량과 같은 핵심 시스템에서 중요한 역할을 합니다. 하지만 높은 성능을 달성하기 위해서는 대량의 annotated data를 필요로 합니다. 이러한 비용을 줄이기 위한 다양한 접근법이 제안되었으며, 예를 들어 semi-supervision, weak supervision, active learning, 그리고 self-supervision 기반의 task fine-tuning 등이 있다.

본 연구에서는 **annotation 없이 이미지를 통해 object의 localizing**하는 방법을 다룬다. 초기 연구들은 **saliency** 또는 이미지 내 유사성(intra-image similarity)만을 활용했으나, 이는 정확도가 낮고 제안된 영역이 너무 많아 대규모 데이터셋에는 적합하지 않았다. 일부 접근법은 annotation 없이 extra modalities(e.g., audio, LiDAR) 등을 활용하기도 했다.

이에 대해, 논문에서 **unsupervised 방식으로 단일 이미지 수준에서 object를 localizing**하는 간단한 방법을 제안합니다. 이 방법은 이미지 간 유사성을 탐색하지 않기 때문에 선형적인 복잡도를 가지며, 대규모 데이터셋에서도 높은 확장성을 가집니다.
<br>

#### Idea
**[DINO(Self-supervised Vision Transformer)](https://arxiv.org/pdf/2104.14294)**에서 학습된 고품질 특징을 활용한다. 구체적으로:
\1. 이미지를 동일한 크기의 패치로 나눈다.
\2. DINO 모델을 통해 각 패치의 특징을 추출한다.
\3. 마지막 attention 레이어에서 key component를 사용하여여 패치 간 유사도를 계산한다.
\4. **유사한 패치 수가 가장 적은 패치(Seed)**를 선택해 object의 일부를 localize한다. 이는 foreground objects의 패치가 background 패치보다 상관성이 낮다는 empirical criterion 기반했다.
\5. 초기 Seed에 대해 유사성이 높은 패치를 추가하며, 이를 **Seed 확장(Seed Expansion)**이라고 힌다.
\6. 최종적으로 이 과정을 통해 **binary object segmentation mask**를 생성하고, 연결된 가장 큰 구성 요소에 대해 **bounding box**를 추론한다.
<br한

#### Contribution
이 연구는 다음과 같은 주요 성과를 달성했다.
1. Self-supervised pre-trained Vision Transformer에서 추출한 feature와 patch 간의 상관관계를 활용하여, region proposals 및 기존의 single-object discovery 방법을 능가하는 성능을 보이는 간단한 single-object localization 방법을 제안했다.
2. 제안된 방법론을 활용하여 클래스에 구애받지 않는 (class-agnostic) 객체 탐지기를 학습시켰으며, 이를 통해 단일 이미지에서 다중 객체를 정확히 탐지할 수 있었다.
3. 탐지된 객체를 시각적으로 일관된 클래스로 클러스터링하여 class-aware object detector를 학습시켰다.
4. 일부 클러스터는 데이터셋의 라벨된 의미적 클래스와 높은 상관성을 보여, weakly-supervised 학습 수준의 객체 탐지 결과를 달성했다.

이 연구는 비지도 학습의 잠재력을 보여주며, 대규모 데이터셋에 주석을 달지 않고도 정확한 객체 탐지를 가능하게 한다는 점에서 큰 의미를 갖는다.