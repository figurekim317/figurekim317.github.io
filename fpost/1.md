---
layout: fpost
title: "Project 1"
permalink: /fpost/1/
#date:   2017-05-26 15:05:55 +0300
image:  /assets/images/blog/post-5.jpg
author: Jongwan Kim
tags:   Autonomy, Object detection, Segmentation, Model Compression, Optimization
---

### • Goal
#### \- Build a model that can perform stable computer vision tasks in an environment with limited resources
- \- Nvidia Xavier resource
    - CPU: 8-core ARM v8.2 64-bit CPU (Custom NVIDIA Carmel)
    - GPU: Volta Architecture with 512 NVIDIA CUDA cores and 64 Tensor Cores
    - RAM: 16 GB 256-bit LPDDR4x memory
    - USB: 4 USB 3.1 Gen 1 ports, 1 USB 3.1 Gen 2 port, 1 USB-C port
    - Camera: 2 MIPI CSI-2 D-PHY lanes, up to 16 simultaneous cameras

#### \- Refactoring of existing lagacy code
- Inputs come in real time through multiple sensors and are given as inputs to deeplearning models through fusion.

#### \- Instance segmentation possible model study using segmentation dataset


### 1. Object Detection: Network Design and Optimization

#### • YOLOv5 Model Performance Improvement and Pruning
- \- Conducted pruning for YOLOv5-based model performance improvement and lightweight design.

<figure>
  <div style="text-align:center">
    <div style="display:inline-block; margin-right:10px;">
      <img src="\fpost\images\pf1\yolov5 capture0.png" alt="대체 텍스트" style="width:100%;">
    </div>
    <div style="display:inline-block;">
      <img src="\fpost\images\pf1\yolov5 capture1.png" alt="대체 텍스트" style="width:100%;">
    </div>
  </div>
  <figcaption style="text-align:center">이미지 설명</figcaption>
</figure>


#### • Class Imbalanced Problem Solution
- \- Solved class imbalance problem by reflecting the numerical measurement of data overlap (effective number) in the loss function.

<figure>
  <div style="text-align:center">
    <img src="\fpost\images\pf1\class imbalanced problem.png" alt="대체 텍스트" style="width:70%;">
  </div>
  <figcaption style="text-align:center">이미지 설명</figcaption>
</figure>

### 2. Segmentation Model: Network Design and Optimization

#### • Model Exploration and Adaptation
- \- Utilized various models such as DDRNet, DeepLab V3+, and ESPNet.
- \- Optimized models for autonomous driving situations through lightweight design and structural optimization.

<figure>
  <div style="text-align:center">
    <img src="\fpost\images\pf1\segmentation 0.png" alt="대체 텍스트" style="width:70%;">
  </div>
  <figcaption style="text-align:center">이미지 설명</figcaption>
</figure>

<style>
table {
  margin-left: auto;
  margin-right: auto;
  border-collapse: collapse;
  width: 70%;
}
th, td {
  border: 1px solid black;
  padding: 8px;
  text-align: center;
}
th {
  background-color: #f2f2f2;
}

td:nth-child(1) {
  width: 25%;
}
td:nth-child(2) {
  width: 15%;
}
td:nth-child(3) {
  width: 15%;
}
td:nth-child(4) {
  width: 45%;
}
</style>


#### • Model Comparison

| Model        | Model Size | Inference Speed (FPS) | Accuracy (Cityscapes dataset) |
|--------------|------------|-----------------------|-------------------------------|
| LiteSeg      | 1.2 MB     | 88.2                  | 70.6 mIoU                     |
| EfficientPS  | 4.3 MB     | 23.5                  | 72.3 mIoU                     |
| FastDepthSeg | 1.9 MB     | 140.8                 | 70.1 mIoU                     |
| DDRNet       | 7.5 MB     | 82.7                  | 78.2 mIoU                     |
| DeepLab V3+  | 8.4 MB     | 37.6                  | 77.7 mIoU                     |

<figure>
  <div style="text-align:center">
    <img src="\fpost\images\pf1\segmentation 1.png" alt="대체 텍스트" style="width:60%;">
  </div>
  <figcaption style="text-align:center">이미지 설명</figcaption>
</figure>

<figure>
  <div style="text-align:center">
    <img src="\fpost\images\pf1\segmentation 2.png" alt="대체 텍스트" style="width:60%;">
  </div>
  <figcaption style="text-align:center">이미지 설명</figcaption>
</figure>



### 3. Model Quantization and Comparison
- \- Applied static quantization, dynamic quantization, and quantization-aware training.
- \- Compared the performance of different models.

#### • Quantization Results

<style>
table {
  margin-left: auto;
  margin-right: auto;
  border-collapse: collapse;
  width: 70%;
}
th, td {
  border: 1px solid black;
  padding: 8px;
  text-align: center;
}
th {
  background-color: #f2f2f2;
}

td:nth-child(1) {
  width: 10%;
}
td:nth-child(2) {
  width: 30%;
}
td:nth-child(3) {
  width: 30%;
}
td:nth-child(4) {
  width: 30%;
}
</style>


| Model       | Quantization-aware Training  | Post Static Quantization  | Post Dynamic Quantization |
|-------------|:----------------------------:|:-------------------------:|:--------------------------:|
|             | mIoU / Model Size / FPS       | mIoU / Model Size / FPS   | mIoU / Model Size / FPS     |
|-------------|-------------------------------|------------------------------|-------------------------------|
| LiteSeg     | 65.1 / 0.6 MB / 172.4         | 62.8 / 0.5 MB / 194.5        | 64.0 / 0.6 MB / 178.7          |
| EfficientPS | 68.7 / 2.15 MB / 45.9         | 65.3 / 1.7 MB / 57.1         | 67.0 / 2.15 MB / 51.3          |
| FastDepthSeg| 67.0 / 0.95 MB / 274.6        | 64.8 / 0.8 MB / 294.8        | 65.8 / 0.95 MB / 281.3         |
| DDRNet      | 73.4 / 3.75 MB / 160.2        | 71.0 / 3.2 MB / 185.3        | 72.4 / 3.75 MB / 171.4         |
| DeepLab V3+ | 69.7 / 4.2 MB / 72.9          | 67.5 / 3.5 MB / 87.4         | 68.8 / 4.2 MB / 79.6           |

| Model       | % Improvement: Quant-aware Train | % Improvement: Static Quant | % Improvement: Dynamic Quant |
|-------------|----------------------------------|------------------------------|-------------------------------|
| LiteSeg     | 96.5%                          | 96.6%                       | 96.3%                         |
| EfficientPS | 97.4%                          | 96.5%                       | 96.9%                         |
| FastDepthSeg| 97.0%                          | 96.5%                       | 96.8%                         |
| DDRNet      | 97.1%                          | 96.1%                       | 96.6%                         |
| DeepLab V3+ | 98.1%                          | 97.9%                       | 98.0%                         |

| Model         | Quantization-aware Training   | Post Static Quantization   | Post Dynamic Quantization   |
| -------------|:-----------------------------:|:---------------------------:|:----------------------------:|
|               | mIoU / Model Size Decrease (%) / RAM Usage Decrease (%)  | mIoU / Model Size Decrease (%) / RAM Usage Decrease (%) | mIoU / Model Size Decrease (%) / RAM Usage Decrease (%) |
| -------------|-------------------------------|------------------------------|-------------------------------|
| LiteSeg       | -4.3 / 16.7 / 0               | -2.6 / 16.7 / -7             | -1.8 / 0 / -5                 |
| EfficientPS   | -4.8 / 15.5 / -17             | -4.8 / 20.9 / -7             | -2.6 / 15.5 / -12             |
| FastDepthSeg  | -2.2 / 2.3 / 42               | -3.3 / 10.5 / 14             | -1.9 / 2.3 / 23               |
| DDRNet        | -3.3 / 9.7 / 44               | -3.3 / 13.3 / 22             | -1.8 / 9.7 / 36               |
| DeepLab V3+   | -2.7 / 19 / 56                | -2.9 / 16.7 / 38             | -1.6 / 19 / 48                |



#### • ONNX Conversion and Optimization
- \- Performed ONNX conversion and optimization for better deployment

#### • TensorRT Optimization for Nvidia Xavier Environment
- \- Optimized models using TensorRT for inference on Nvidia Xavier devices
- \- Achieved significant improvement in inference speed while maintaining acceptable accuracy levels

### 4. Legacy Code Refactoring

#### • GStreamer Pipeline Optimization
- \- Optimized GStreamer-based pipeline

#### • Decoding Improvement
- \- Replaced SW decoding with HW decoding to reduce CPU overhead

#### • Sensor Input and Modularization
- \- Directed various sensor inputs to the HW decoding module
- \- Modularized GStreamer and improved the deep learning model loading process using plugin loader

### 5. Weakly Supervised Instance Segmentation Model Development

- \- Developed weakly supervised instance segmentation model using semantic segmentation data